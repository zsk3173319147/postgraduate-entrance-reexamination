- #### 什么是套接字(Socket)，Linux中套接字的实现原理是什么？

  > 套接字（Socket）是一种在网络上运行的进程间通信机制，它提供了一种标准的接口，使得不同的进程间可以进行通信。在Linux中，套接字是一种文件类型，可以通过打开文件方式创建和访问。
  >
  > 在Linux中，套接字的实现原理是基于内核的网络协议栈。当一个进程创建一个套接字并向其绑定一个端口号时，内核会在网络协议栈中创建一个相应的套接字结构体。当其他进程向该套接字绑定的端口号发送数据时，内核会将数据包交给协议栈中的套接字结构体进行处理。
  >
  > Linux中的套接字可以基于不同的协议，如TCP、UDP、ICMP等。不同的协议有着不同的特点和应用场景。例如，TCP协议提供可靠的数据传输，适合对数据传输的可靠性有较高要求的应用；而UDP协议则不保证数据传输的可靠性，适合对数据实时性要求较高的应用。
  >
  > 总之，套接字在Linux中的实现原理是基于内核的网络协议栈，并可以基于不同的协议实现不同的应用场景


> 当TCP连接的两端都已关闭了TCP连接时，为什么TCP主动关闭的一端还要在状态TIME_WAIT下等待一段时间才删除原来的连接记录，并返回到初始的CLOSED状态。

执行主动关闭的一端进入TIME_WAIT状态，并且留在该状态的持续时间是报文最长生命周期的两倍，有时称为2MSL(Maximum Segment Lifetime)。

(1) 实现终止TCP连接的可靠性，如果终止连接的第4个分节ACK丢失了，那么主动关闭者必须重发。假设主动关闭的一端忽略TIME_WAIT状态，直接进入CLOSED状态， **被动关闭的一端会以为之前发送的FIN包对方没有收到，会重新发送一个FIN包**。这时主动关闭的一端收到该FIN后发现旧的TCP连接已经不存在了，系统此时只能返回 RST包。

(2) 保证原来连接上的重复分节在网络中消失。假设主动关闭的一端忽略TIME_WAIT状态，直接进入CLOSED状态。这时主动关闭端可能收到延迟包，若此时已经建立了 新的TCP连接，这种来自于**旧TCP连接中延迟包很可能会干扰新建立的TCP连接**。由此可以看出TIME_WAIT的重要性，主动关闭端可以在2MSL的时段内处理遗留问题。



> 简述通用套接字地址结构的作用。

套接字地址结构作为参数传递给任一个套接字函数时，通常通过指针来传递。当套接字函数取得此参数时，参数中可能存放的是来自所支持的**任何协议族的地址结构**。因此在调用套接字函数时，需要将指向**特定**于协议的地址结构的指针类型转换成指向**通用地址结构**的指针。

```c
struct sockaddr_in ser;
bind(sockfd, (struct sockaddr *)&ser, sizeof(ser));
```

> 简述字节排序函数的作用。

由于网络上的主机可能采用不同的主机字节序，所以字节排序函数可以**将不同的主机字节序转换成网络字节序**，从而使网络上不同的主机之间能够相互通信。



> 简述使用TCP套接字编程的基本步骤。

**服务端实现的步骤如下：**

1. **使用socket()函数创建套接字。**
2. **将创建的套接字绑定到指定的地址结构。**
3. **listen()函数设置套接字为监听模式，使服务器进入被动打开的状态。**
4. **接受客户的连接请求，建立连接。**
5. **接收、应答客户端的数据请求。**

**客户端实现的步骤如下：**

1. **使用socket()函数创建套接字。**
2. **调用connect()函数建立一个与TCP服务器的连接。**
3. **发送数据请求，接收服务器的数据应答。**
4. **终止连接。**



> 简述使用UDP套接字编程的基本步骤。

服务器端：

1. 使用socket()函数创建套接字。
2. 将创建的套接字绑定到指定的地址结构。
3. 等待客户端的数据请求。
4. 处理客户端请求。
5. 向客户端发送应答数据。
6. 关闭套接字

客户端：

1. 使用socket()函数创建套接字。
2. 发送数据请求给服务器。
3. 等待接收服务器的数据应答。
4. 关闭套接字。



> 简述使用TCP套接字基本函数编程的过程中，TCP链接的状态变化。

- 服务端依次执行：socket(),bind(),listen()后状态变为 **LISTEN** ，accept()阻塞。
- 客户端依次执行：socket(),connect()后状态变为 **SYN_SENT** ，发送SYN J 。
- 服务端收到SYN J，状态变为 **SYN_RCVD** ，发送 SYN K 、ACK J + 1。
- 客户端收到SYN K、ACK j + 1，状态变为 **ESTABLISHED** ，发送 ACK K + 1。
- 服务端收到ACK K + 1，状态变为 **ESTABLISHED**，accept()返回。



- Linux系统主要提供3种方式支持并发：进程、线程、I/O多路复用。
- Linux有3种资源拷贝的方式：共享(vfork)、直接拷贝、Copy on Write(fork)。
- fork()函数，如果调用成功，该函数返回2次。在父进程中返回子进程ID号，在子进程中返回0。

- 如果父进程在子进程之前终止，则所有子进程的父进程被改为init进程，就是由init进程**领养**。
- 一个已经终止但是其父进程尚未对其进行善后处理的进程称为**僵尸进程**。



> 什么是守护进程？它与后台运行的程序有什么区别？

1. 守护进程是在后台运行不受终端控制的进程（如输入、输出等）。
2. 加&启动的程序是后台运行的程序，虽然运行时与守护进程相似，但它拥有控制终端。





> 创建守护进程的步骤是什么？

1. 调用frok()函数产生后台子进程，然后终止父进程，留下子进程继续运行。
2. 调用setid()函数产生新的会话期并失去控制终端。
3. 忽略SIGHUP信号并再次调用fork()函数产生新子进程。终止第一个子进程。
4. 改变工作目录。（通常将目录改变到根目录下）
5. 关闭已打开的文件描述符，并打开一个空设备，把它复制到标准输出、标准错误上。
6. 用openlog()函数建立与syslogd的连接。



>  linux的5种I/O模型

目前Linux下可用的IO模型有5种，分别为阻塞IO、非阻塞IO、IO多路复用、信号驱动IO、异步IO，其中较为成熟且高效、稳定的是IO多路复用模型，因此当前众多网络服务程序几乎都是采用这种IO操作策略。

- 阻塞IO

  所谓阻塞IO就是当应用B发起读取数据申请时，在内核数据没有准备好之前，应用B会一直处于等待数据状态，直到内核把数据准备好了交给应用B才结束。

  **在应用调用recvfrom读取数据时，其系统调用直到数据包到达且被复制到应用缓冲区中或者发送错误时才返回，在此期间一直会等待，进程从调用到返回这段时间内都是被阻塞的称为阻塞IO；**

- 非阻塞IO

  在有些时候并不希望进程在IO操作未完成时睡眠，而是希望系统调用能够立刻返回一个错误，以报告这一情况，然后进程可以根据需要在适当的时候再重新执行这个IO操作。这就是所谓的非阻塞IO模型。

  非阻塞IO是在应用调用recvfrom读取数据时，如果该缓冲区没有数据的话，就会直接返回一个EWOULDBLOCK错误，不会让应用一直等待中。在没有数据的时候会即刻返回错误标识，那也意味着如果应用要读取数据就需要不断的调用recvfrom请求，直到读取到它数据要的数据为止。

- IO多路复用

  能不能提供一种方式，可以由一个线程监控多个网络请求（**我们后面将称为fd文件描述符，linux系统把所有网络请求以一个fd来标识**），这样就可以只需要一个或几个线程就可以完成数据状态询问的操作，当有数据准备就绪之后再分配对应的线程去读取数据，这么做就可以节省出大量的线程资源出来，这个就是IO复用模型的思路。

  进程通过将一个或多个fd传递给select，阻塞在select操作上，select帮我们侦测多个fd是否准备就绪，当有fd准备就绪时，select返回数据可读状态，应用程序再调用recvfrom读取数据。(fd就是网络请求)

  复用IO的基本思路就是通过slect或poll、epoll 来监控多fd ，来达到不必为每个fd创建一个对应的监控线程，从而减少线程资源创建的目的。

- 信号驱动IO模型

  于是信号驱动IO不是用循环请求询问的方式去监控数据就绪状态，而是在调用sigaction时候建立一个SIGIO的信号联系，当内核数据准备好之后再通过SIGIO信号通知线程数据准备好后的可读状态，当线程收到可读状态的信号后，此时再向内核发起recvfrom读取数据的请求，因为信号驱动IO的模型下应用线程在发出信号监控后即可返回，不会阻塞，所以这样的方式下，一个应用线程也可以同时监控多个fd。

  首先开启套接口信号驱动IO功能，并通过系统调用sigaction执行一个信号处理函数，此时请求即刻返回，当数据准备就绪时，就生成对应进程的SIGIO信号，通过信号回调通知应用线程调用recvfrom来读取数据。

- 异步IO模型

  应用告知内核启动某个操作，并让内核在整个操作完成之后，通知应用，这种模型与信号驱动模型的主要区别在于，信号驱动IO只是由内核通知我们合适可以开始下一个IO操作，而异步IO模型是由内核通知我们操作什么时候完成。

> **select、poll、epoll 区别总结：**

1、支持一个进程所能打开的最大连接数

select

单个进程所能打开的最大连接数有FD_SETSIZE宏定义，其大小是32个整数的大小（在32位的机器上，大小就是32*32，同理64位机器上FD_SETSIZE为32*64），当然我们可以对进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步的测试。

poll

poll本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的

epoll

虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右的连接

2、FD剧增后带来的IO效率问题

select

因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题”。

poll

同上

epoll

因为epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题。

3、 消息传递方式

select

内核需要将消息传递到用户空间，都需要内核拷贝动作

poll

同上

epoll

epoll通过内核和用户空间共享一块内存来实现的。

**总结：**

**综上，在选择select，poll，epoll时要根据具体的使用场合以及这三种方式的自身特点。**

**1、表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。**

**2、select低效是因为每次它都需要轮询。但低效也是相对的，视情况而定，也可通过良好的设计改善** 

 